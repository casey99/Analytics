{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d00da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "import traceback\n",
    "from retrying import retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed61111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_webpage(url):\n",
    "    \"\"\"\n",
    "    Fetches the content of a webpage using requests.\n",
    "    \n",
    "    Parameters:\n",
    "        url (str): The URL of the webpage.\n",
    "        \n",
    "    Returns:\n",
    "        str: The HTML content of the webpage.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def parse_html(html_content):\n",
    "    \"\"\"\n",
    "    Parses HTML content using Beautiful Soup.\n",
    "    \n",
    "    Parameters:\n",
    "        html_content (str): The HTML content to parse.\n",
    "        \n",
    "    Returns:\n",
    "        BeautifulSoup: A BeautifulSoup object representing the parsed HTML.\n",
    "    \"\"\"\n",
    "    return BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ad40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PAGES=23\n",
    "list_url = [f'https://www.airlinequality.com/airline-reviews/aer-lingus/page/{page}/?sortby=post_date%3ADesc&pagesize=100' for page in range(1, MAX_PAGES + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a98dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_data = pd.DataFrame(columns=['Date Published', 'Overall Rating', 'Passenger Country', 'Trip_verified', 'Comment title','Comment', \n",
    "                                       'Aircraft', 'Type Of Traveller', 'Seat Type', 'Origin', 'Destination' 'Date Flown', \n",
    "                                       'Seat Comfort', 'Cabin Staff Service', 'Food & Beverages', 'Ground Service', \n",
    "                                       'Value For Money', 'Recommended'])\n",
    "comments_data_list = [] \n",
    "\n",
    "class_to_label = {\n",
    "    'aircraft': 'Aircraft',\n",
    "    'type_of_traveller': 'Type Of Traveller',\n",
    "    'cabin_flown': 'Seat Type',\n",
    "    'route': 'Route',\n",
    "    'date_flown': 'Date Flown',\n",
    "    'seat_comfort': 'Seat Comfort',\n",
    "    'cabin_staff_service': 'Cabin Staff Service',\n",
    "    'food_and_beverages': 'Food & Beverages',\n",
    "    'inflight_entertainment':'Inflight Entertainment',\n",
    "    'ground_service': 'Ground Service',\n",
    "    'wifi_and_connectivity':'Wifi & Connectivity',\n",
    "    'value_for_money': 'Value For Money',\n",
    "    'recommended': 'Recommended'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ae692e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing comment at URL section 'ge', Comment Index: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/tr/cyhtsz016w388n4xcfp_x8w40000gn/T/ipykernel_40138/92741421.py\", line 69, in <module>\n",
      "    origin, destination, _ = value.split('-')\n",
      "ValueError: too many values to unpack (expected 3)\n"
     ]
    }
   ],
   "source": [
    "# Loop through each URL in the list of URLs\n",
    "for url in list_url:\n",
    "    # Fetch the webpage content\n",
    "    html_content = fetch_webpage(url)\n",
    "    \n",
    "    # Proceed if the webpage content was successfully fetched\n",
    "    if html_content:\n",
    "        # Parse the HTML content\n",
    "        soup = parse_html(html_content)\n",
    "        \n",
    "        # Find all comment elements (reviews) within 'article' tags\n",
    "        comments = soup.find_all('article', itemprop='review')  # Retrieve only the first 5 comments\n",
    "        \n",
    "        # Process each comment found on the page\n",
    "        for comment in comments:\n",
    "            try:\n",
    "                # Extract the publication date\n",
    "                date_published = comment.find('meta', itemprop='datePublished')['content']\n",
    "                \n",
    "                # Retrieve the rating value, if available\n",
    "                rating = comment.find('span', itemprop='ratingValue')\n",
    "                rating = rating.text if rating else ''\n",
    "                \n",
    "                # Extract the comment header (title)\n",
    "                text_header = comment.find('h2', class_='text_header').text\n",
    "                \n",
    "                # Retrieve sub-header text, which contains the user's country\n",
    "                text_sub_header_text = comment.find('h3', class_='text_sub_header userStatusWrapper').get_text(strip=True)\n",
    "                country = text_sub_header_text.split('(')[-1].split(')')[0]\n",
    "                \n",
    "                # Extract the main content of the review\n",
    "                text_content = comment.find('div', class_='text_content', itemprop='reviewBody')\n",
    "                \n",
    "                # Determine whether the trip was verified or not\n",
    "                verification = text_content.find('strong')\n",
    "                verification = verification.text.strip() if verification else ''\n",
    "                \n",
    "                # Clean up the text content of the review\n",
    "                text_content = text_content.text.strip()\n",
    "                if '|' in text_content:\n",
    "                    text_content = text_content.split('|')[1].strip()\n",
    "                \n",
    "                # Locate the review ratings table for specific feature ratings\n",
    "                review_ratings = comment.find('table', class_='review-ratings')\n",
    "                review_ratings = review_ratings.find_all('tr')\n",
    "                \n",
    "                # Dictionary to store extracted ratings data\n",
    "                table_data = {}\n",
    "                for row in review_ratings:\n",
    "                    # Extract the header and value cells\n",
    "                    header_cell = row.find('td', class_='review-rating-header')\n",
    "                    value_cell = row.find('td', class_='review-value')\n",
    "                    value2_cell = row.find('td', class_='review-rating-stars')\n",
    "                    \n",
    "                    # If both header and either value cell exist, proceed to extract\n",
    "                    if header_cell and (value_cell or value2_cell):\n",
    "                        # Retrieve the feature label from the cell class\n",
    "                        class_name = header_cell['class'][1]\n",
    "                        data_label = class_to_label.get(class_name, '')\n",
    "                        \n",
    "                        # Process the rating value for each feature\n",
    "                        if value_cell:\n",
    "                            value = value_cell.text.strip()\n",
    "                            # For 'Route' values, split into origin and destination\n",
    "                            if data_label == 'Route':\n",
    "                                if 'to' in value:\n",
    "                                    origin, destination = value.split(' to ')\n",
    "                                elif '-' in value:\n",
    "                                    origin, destination, _ = value.split('-')\n",
    "                                table_data['Origin'] = origin.strip()\n",
    "                                table_data['Destination'] = destination.strip()\n",
    "                            else:\n",
    "                                table_data[data_label] = value\n",
    "                        else:\n",
    "                            # If using stars, count filled stars\n",
    "                            filled_star_spans = value2_cell.find_all('span', class_='star fill')\n",
    "                            table_data[data_label] = int(len(filled_star_spans))\n",
    "\n",
    "                # Add the extracted data to the comments data list\n",
    "                comments_data_list.append({\n",
    "                    'Date Published': date_published,\n",
    "                    'Overall Rating': rating,\n",
    "                    'Passenger Country': country,\n",
    "                    'Trip Verified': verification,\n",
    "                    'Comment Title': text_header,\n",
    "                    'Comment': text_content,\n",
    "                    **table_data\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in processing comment at URL section '{url[60:62]}', Comment Index: {comments.index(comment)}\")\n",
    "                traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a67a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_data = pd.DataFrame(comments_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cccba552",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_data.to_csv('Aerlingus_reviews.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec5f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
